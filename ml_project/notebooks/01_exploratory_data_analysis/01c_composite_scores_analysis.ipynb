{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1C: Composite Score Analysis\n",
    "\n",
    "**Objective:** Analyze which of the 7 squad-level composite score categories predict final league position.\n",
    "\n",
    "**Key Questions:**\n",
    "1. Which composite categories best predict final position?\n",
    "2. Are any categories redundant (highly correlated)?\n",
    "3. What scores separate Top 4 from relegation?\n",
    "4. Why is Arsenal dominating GW7?\n",
    "5. Which categories should we prioritize for ML modeling?\n",
    "\n",
    "**Data:**\n",
    "- Historical: 3 recent complete seasons with GW38 final positions\n",
    "- Current: 2025-2026 season at GW7\n",
    "- Categories: 7 squad composite scores (attacking_output, creativity, defending, ball_progression, physical_duels, passing, possession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path to import SquadAnalyzer\n",
    "project_root = Path.cwd().parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PART 1C: COMPOSITE SCORE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚è∞ Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "# Database path (will connect after SquadAnalyzer to avoid conflicts)\n",
    "db_path = str(project_root / \"data\" / \"premierleague_analytics.duckdb\")\n",
    "print(f\"‚úÖ Database: {db_path}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Define Seasons to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìÖ Defining Historical Seasons to Analyze...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Temporarily connect to get available seasons\n",
    "conn_temp = duckdb.connect(db_path, read_only=True)\n",
    "\n",
    "# Get available seasons with GW38 data (completed seasons)\n",
    "available_seasons = conn_temp.execute(\"\"\"\n",
    "    SELECT DISTINCT season\n",
    "    FROM analytics_squads\n",
    "    WHERE gameweek = 38\n",
    "    ORDER BY season DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Close temporary connection to avoid conflicts with SquadAnalyzer\n",
    "conn_temp.close()\n",
    "\n",
    "print(f\"Available complete seasons: {len(available_seasons)}\")\n",
    "for season in available_seasons['season']:\n",
    "    print(f\"  - {season}\")\n",
    "print()\n",
    "\n",
    "# Choose recent seasons to analyze\n",
    "seasons_to_analyze = available_seasons['season'].head(5).tolist()\n",
    "\n",
    "print(f\"üìä Analyzing these {len(seasons_to_analyze)} recent seasons:\")\n",
    "for season in seasons_to_analyze:\n",
    "    print(f\"  ‚úÖ {season}\")\n",
    "print()\n",
    "\n",
    "print(f\"üí° Note: Using recent seasons for faster analysis.\")\n",
    "print(f\"   You can expand to all {len(available_seasons)} seasons later if needed.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Import SquadAnalyzer and Define Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Loading SquadAnalyzer...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    from analysis.squad_analyzer import SquadAnalyzer\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = SquadAnalyzer(db_path=db_path)\n",
    "    analyzer.connect()\n",
    "    \n",
    "    print(\"‚úÖ SquadAnalyzer loaded successfully\")\n",
    "    \n",
    "    # Get the 7 squad composite categories (not 8 - that's for players)\n",
    "    categories = list(analyzer.stat_categories.keys())\n",
    "    \n",
    "    print(f\"\\nüìã Analyzing {len(categories)} squad composite categories:\")\n",
    "    for i, cat in enumerate(categories, 1):\n",
    "        print(f\"   {i}. {cat}\")\n",
    "    print()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not load SquadAnalyzer: {e}\")\n",
    "    raise\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Calculate Composite Scores for All Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 4: CALCULATING COMPOSITE SCORES (Season-by-Season)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"This will take 2-5 minutes...\")\n",
    "print(f\"Processing: {len(seasons_to_analyze)} seasons √ó {len(categories)} categories √ó 20 teams\")\n",
    "print(f\"Total calculations: {len(seasons_to_analyze) * len(categories) * 20}\")\n",
    "print()\n",
    "\n",
    "# Store all composite scores\n",
    "all_composite_scores = []\n",
    "\n",
    "# Loop through each season\n",
    "for season_idx, season in enumerate(seasons_to_analyze, 1):\n",
    "    print(f\"[{season_idx}/{len(seasons_to_analyze)}] Processing season {season}...\")\n",
    "    \n",
    "    timeframe = f\"season_{season}\"\n",
    "    \n",
    "    # Loop through each category\n",
    "    for cat_idx, category in enumerate(categories, 1):\n",
    "        try:\n",
    "            # Calculate composite scores for this category in this season\n",
    "            # This automatically ranks teams 1-20 WITHIN this season\n",
    "            scores_df = analyzer.calculate_category_composite_scores(\n",
    "                category=category,\n",
    "                timeframe=timeframe\n",
    "            )\n",
    "            \n",
    "            if not scores_df.empty:\n",
    "                # Add season and category columns\n",
    "                scores_df['season'] = season\n",
    "                scores_df['category'] = category\n",
    "                \n",
    "                # Store\n",
    "                all_composite_scores.append(scores_df)\n",
    "                \n",
    "                # Progress indicator\n",
    "                if cat_idx % 3 == 0:  # Print every 3 categories\n",
    "                    print(f\"  ‚úì Processed {cat_idx}/{len(categories)} categories for {season}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Error calculating {category} for {season}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"  ‚úÖ Completed {season}\")\n",
    "    print()\n",
    "\n",
    "# Combine all results\n",
    "if all_composite_scores:\n",
    "    composite_df = pd.concat(all_composite_scores, ignore_index=True)\n",
    "    print(f\"‚úÖ Successfully calculated composite scores!\")\n",
    "    print(f\"   Total records: {len(composite_df)}\")\n",
    "    print(f\"   Seasons: {composite_df['season'].nunique()}\")\n",
    "    print(f\"   Categories: {composite_df['category'].nunique()}\")\n",
    "    print(f\"   Unique squads: {composite_df['squad_name'].nunique()}\")\n",
    "else:\n",
    "    print(\"‚ùå No composite scores calculated!\")\n",
    "    raise Exception(\"Failed to calculate composite scores\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Disconnect analyzer\n",
    "analyzer.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Load Historical Match Results with Final Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 5: LOADING HISTORICAL MATCH RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Reconnect to database (SquadAnalyzer has disconnected by now)\n",
    "conn = duckdb.connect(db_path, read_only=True)\n",
    "\n",
    "# Load historical season-end data with final positions\n",
    "historical = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        season,\n",
    "        squad_name,\n",
    "        gameweek,\n",
    "        matches_played,\n",
    "        goals,\n",
    "        goals_against,\n",
    "        (goals - goals_against) as goal_difference,\n",
    "        wins,\n",
    "        draws,\n",
    "        losses,\n",
    "        (wins * 3 + draws) as points\n",
    "    FROM analytics_squads\n",
    "    WHERE gameweek = 38\n",
    "        AND season IN (?, ?, ?, ?, ?)\n",
    "    ORDER BY season DESC, points DESC\n",
    "\"\"\", seasons_to_analyze).fetchdf()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(historical)} historical squad records\")\n",
    "print()\n",
    "\n",
    "# Calculate final position WITHIN each season\n",
    "historical['final_position'] = historical.groupby('season')['points'].rank(\n",
    "    method='min', ascending=False\n",
    ").astype(int)\n",
    "\n",
    "# Assign tiers\n",
    "def get_tier(position):\n",
    "    if position <= 4:\n",
    "        return 'Top 4'\n",
    "    elif position <= 10:\n",
    "        return 'Upper Mid-Table (5-10)'\n",
    "    elif position <= 17:\n",
    "        return 'Lower Mid-Table (11-17)'\n",
    "    else:\n",
    "        return 'Relegation Zone (18-20)'\n",
    "\n",
    "historical['tier'] = historical['final_position'].apply(get_tier)\n",
    "\n",
    "# Display tier distribution\n",
    "print(\"üìä Tier Distribution Across Seasons:\")\n",
    "tier_dist = historical.groupby(['season', 'tier']).size().unstack(fill_value=0)\n",
    "print(tier_dist)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Merge Composite Scores with Historical Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 6: MERGING COMPOSITE SCORES WITH HISTORICAL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Pivot composite scores to wide format (one row per squad per season)\n",
    "composite_wide = composite_df.pivot_table(\n",
    "    index=['season', 'squad_name'],\n",
    "    columns='category',\n",
    "    values='composite_score',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns to add '_score' suffix\n",
    "composite_wide.columns = [f\"{col}_score\" if col not in ['season', 'squad_name'] else col \n",
    "                          for col in composite_wide.columns]\n",
    "\n",
    "print(f\"‚úÖ Pivoted composite scores to wide format\")\n",
    "print(f\"   Shape: {composite_wide.shape}\")\n",
    "print()\n",
    "\n",
    "# Merge with historical data\n",
    "historical_with_composites = historical.merge(\n",
    "    composite_wide,\n",
    "    on=['season', 'squad_name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Merged composite scores with historical data\")\n",
    "print(f\"   Final shape: {historical_with_composites.shape}\")\n",
    "print()\n",
    "\n",
    "# Check for missing composite scores\n",
    "composite_cols = [col for col in historical_with_composites.columns if col.endswith('_score')]\n",
    "print(f\"üìä Composite score columns: {len(composite_cols)}\")\n",
    "\n",
    "missing_summary = []\n",
    "for col in composite_cols:\n",
    "    missing = historical_with_composites[col].isna().sum()\n",
    "    missing_pct = (missing / len(historical_with_composites)) * 100\n",
    "    missing_summary.append({\n",
    "        'category': col.replace('_score', ''),\n",
    "        'missing': missing,\n",
    "        'missing_pct': missing_pct\n",
    "    })\n",
    "\n",
    "missing_df = pd.DataFrame(missing_summary)\n",
    "if missing_df['missing'].sum() > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  Missing composite scores:\")\n",
    "    print(missing_df[missing_df['missing'] > 0])\n",
    "else:\n",
    "    print(\"‚úÖ No missing composite scores!\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Composite Score Distributions by Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 7: COMPOSITE SCORE DISTRIBUTIONS BY TIER\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"../../outputs/03_composite_scores_analysis\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tier_order = ['Top 4', 'Upper Mid-Table (5-10)', 'Lower Mid-Table (11-17)', 'Relegation Zone (18-20)']\n",
    "\n",
    "# Calculate mean scores by tier for each category\n",
    "print(\"üìä MEAN COMPOSITE SCORES BY TIER\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tier_means = {}\n",
    "for col in composite_cols:\n",
    "    tier_means[col] = historical_with_composites.groupby('tier')[col].mean()\n",
    "\n",
    "tier_means_df = pd.DataFrame(tier_means).T\n",
    "tier_means_df.columns = tier_order\n",
    "tier_means_df.index = [idx.replace('_score', '') for idx in tier_means_df.index]\n",
    "\n",
    "print(tier_means_df.round(1))\n",
    "print()\n",
    "\n",
    "# Identify which categories show biggest separation\n",
    "print(\"üí° CATEGORY SEPARATION ANALYSIS (Top 4 vs Relegation)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "separations = {}\n",
    "for col in composite_cols:\n",
    "    top4_mean = historical_with_composites[historical_with_composites['tier'] == 'Top 4'][col].mean()\n",
    "    relegation_mean = historical_with_composites[historical_with_composites['tier'] == 'Relegation Zone (18-20)'][col].mean()\n",
    "    separation = top4_mean - relegation_mean\n",
    "    separations[col] = separation\n",
    "    \n",
    "# Sort by separation (largest first)\n",
    "separations_sorted = sorted(separations.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Categories ranked by Top 4 vs Relegation gap (higher = more predictive):\")\n",
    "for i, (category, sep) in enumerate(separations_sorted, 1):\n",
    "    category_name = category.replace('_score', '')\n",
    "    print(f\"  {i}. {category_name:<25} Gap: {sep:>6.1f} points\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Visualize Composite Scores by Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Creating Composite Score Visualizations...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Determine grid size based on number of categories\n",
    "n_categories = len(composite_cols)\n",
    "n_cols = 3  # 3 columns\n",
    "n_rows = (n_categories + n_cols - 1) // n_cols  # Ceiling division\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, n_rows * 4))\n",
    "axes = axes.flatten() if n_categories > 1 else [axes]\n",
    "\n",
    "tier_colors = {\n",
    "    'Top 4': '#2ecc71',\n",
    "    'Upper Mid-Table (5-10)': '#3498db',\n",
    "    'Lower Mid-Table (11-17)': '#f39c12',\n",
    "    'Relegation Zone (18-20)': '#e74c3c'\n",
    "}\n",
    "\n",
    "for idx, col in enumerate(composite_cols):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Create box plot\n",
    "    sns.boxplot(\n",
    "        data=historical_with_composites,\n",
    "        x='tier',\n",
    "        y=col,\n",
    "        order=tier_order,\n",
    "        palette=tier_colors,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Formatting\n",
    "    category_name = col.replace('_score', '').replace('_', ' ').title()\n",
    "    ax.set_title(category_name, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Composite Score', fontsize=10)\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(len(composite_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle(f'Composite Scores by Final Position Tier ({len(seasons_to_analyze)} Seasons)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"composite_scores_by_tier.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: composite_scores_by_tier.png\")\n",
    "plt.show()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 9: Correlation with Final Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 9: CORRELATION WITH FINAL POSITION\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Calculate correlation between each composite score and final position\n",
    "# Note: Negative correlation = higher score ‚Üí better (lower) position\n",
    "correlations = {}\n",
    "\n",
    "for col in composite_cols:\n",
    "    # Drop NaN values for correlation\n",
    "    valid_data = historical_with_composites[[col, 'final_position']].dropna()\n",
    "    \n",
    "    if len(valid_data) > 0:\n",
    "        corr = valid_data[col].corr(valid_data['final_position'])\n",
    "        correlations[col] = corr\n",
    "\n",
    "# Sort by absolute correlation (strongest predictors first)\n",
    "correlations_sorted = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"üìä CORRELATION WITH FINAL POSITION\")\n",
    "print(\"-\" * 80)\n",
    "print(\"(Negative correlation = higher score ‚Üí better position)\")\n",
    "print()\n",
    "print(f\"{'Category':<30} {'Correlation':<15} {'Strength'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for category, corr in correlations_sorted:\n",
    "    category_name = category.replace('_score', '')\n",
    "    \n",
    "    # Interpret correlation strength\n",
    "    if abs(corr) >= 0.7:\n",
    "        strength = \"üî• Very Strong\"\n",
    "    elif abs(corr) >= 0.5:\n",
    "        strength = \"üí™ Strong\"\n",
    "    elif abs(corr) >= 0.3:\n",
    "        strength = \"üëç Moderate\"\n",
    "    else:\n",
    "        strength = \"üòê Weak\"\n",
    "    \n",
    "    print(f\"{category_name:<30} {corr:>8.3f}        {strength}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Identify top predictors\n",
    "top_predictors = [cat for cat, corr in correlations_sorted if abs(corr) >= 0.5]\n",
    "weak_predictors = [cat for cat, corr in correlations_sorted if abs(corr) < 0.3]\n",
    "\n",
    "print(f\"üí° KEY INSIGHT:\")\n",
    "print(f\"   üî• {len(top_predictors)} strong predictors (|r| ‚â• 0.5): {[c.replace('_score', '') for c in top_predictors]}\")\n",
    "print(f\"   üòê {len(weak_predictors)} weak predictors (|r| < 0.3): {[c.replace('_score', '') for c in weak_predictors]}\")\n",
    "print(f\"\\n   üëâ Focus ML models on the {len(top_predictors)} strong predictors!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 10: Category Correlation Matrix (Redundancy Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 10: CATEGORY CORRELATION MATRIX (Redundancy Check)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Checking for redundant categories (high inter-correlation)...\")\n",
    "print()\n",
    "\n",
    "# Calculate correlation matrix between composite scores\n",
    "composite_data = historical_with_composites[composite_cols].dropna()\n",
    "\n",
    "if len(composite_data) > 0:\n",
    "    corr_matrix = composite_data.corr()\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Clean labels (remove '_score' suffix)\n",
    "    labels = [col.replace('_score', '').replace('_', '\\n') for col in composite_cols]\n",
    "    \n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='coolwarm',\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        square=True,\n",
    "        linewidths=1,\n",
    "        cbar_kws={'label': 'Correlation Coefficient'},\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Correlation Matrix: Composite Scores\\n(High values = potential redundancy)', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / \"composite_correlation_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: composite_correlation_matrix.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Identify highly correlated pairs (r > 0.70)\n",
    "    print(\"\\nüîç HIGHLY CORRELATED PAIRS (|r| > 0.70)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    found_high_corr = False\n",
    "    for i in range(len(composite_cols)):\n",
    "        for j in range(i+1, len(composite_cols)):\n",
    "            corr_val = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.70:\n",
    "                cat1 = composite_cols[i].replace('_score', '')\n",
    "                cat2 = composite_cols[j].replace('_score', '')\n",
    "                print(f\"  {cat1} ‚Üî {cat2}: r = {corr_val:.3f}\")\n",
    "                found_high_corr = True\n",
    "    \n",
    "    if not found_high_corr:\n",
    "        print(\"  ‚úÖ No highly correlated pairs found\")\n",
    "        print(\"  üëâ All categories are distinct - no redundancy!\")\n",
    "    else:\n",
    "        print(\"\\nüí° Consider removing one category from highly correlated pairs\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Not enough data to calculate correlation matrix\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 11: Current Season Analysis (GW7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 11: CURRENT SEASON COMPOSITE SCORES (GW7)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"Calculating composite scores for current season (2025-2026 GW7)...\")\n",
    "\n",
    "# Close the previous connection from Section 5 to avoid conflicts\n",
    "conn.close()\n",
    "\n",
    "# Reconnect analyzer\n",
    "analyzer.connect()\n",
    "\n",
    "# Calculate composite scores for current season\n",
    "current_composites = []\n",
    "\n",
    "for category in categories:\n",
    "    try:\n",
    "        scores_df = analyzer.calculate_category_composite_scores(\n",
    "            category=category,\n",
    "            timeframe='current'  # GW7 snapshot\n",
    "        )\n",
    "        \n",
    "        if not scores_df.empty:\n",
    "            scores_df['category'] = category\n",
    "            current_composites.append(scores_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not calculate {category}: {e}\")\n",
    "\n",
    "# Combine\n",
    "if current_composites:\n",
    "    current_composite_df = pd.concat(current_composites, ignore_index=True)\n",
    "    \n",
    "    # Pivot to wide format\n",
    "    current_wide = current_composite_df.pivot_table(\n",
    "        index='squad_name',\n",
    "        columns='category',\n",
    "        values='composite_score',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(f\"‚úÖ Current season composite scores calculated\")\n",
    "    print(f\"   Squads: {len(current_wide)}\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"‚ùå Could not calculate current season scores\")\n",
    "    current_wide = pd.DataFrame()\n",
    "\n",
    "analyzer.disconnect()\n",
    "\n",
    "# Show top 5 teams by each category\n",
    "if not current_wide.empty:\n",
    "    print(\"üèÜ TOP 5 TEAMS BY CATEGORY (Current Season, GW7)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for category in categories:\n",
    "        if category in current_wide.columns:\n",
    "            print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "            top5 = current_wide.nlargest(5, category)[['squad_name', category]]\n",
    "            for idx, row in top5.iterrows():\n",
    "                print(f\"  {row['squad_name']:<20} {row[category]:.1f}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 12: Arsenal Deep Dive (Why Dominating?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 12: ARSENAL ANALYSIS - Why Are They Dominating GW7?\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# From Part 1B, we know Arsenal leads in goals\n",
    "if not current_wide.empty and 'Arsenal' in current_wide['squad_name'].values:\n",
    "    arsenal_row = current_wide[current_wide['squad_name'] == 'Arsenal'].iloc[0]\n",
    "    \n",
    "    print(\"üîç ARSENAL'S COMPOSITE SCORE PROFILE (GW7)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    arsenal_scores = {}\n",
    "    for category in categories:\n",
    "        if category in current_wide.columns:\n",
    "            score = arsenal_row[category]\n",
    "            arsenal_scores[category] = score\n",
    "            \n",
    "            # Get rank\n",
    "            rank = (current_wide[category] > score).sum() + 1\n",
    "            \n",
    "            print(f\"{category:<25} Score: {score:>6.1f}  Rank: {rank}/20\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Create radar chart for Arsenal\n",
    "    if len(arsenal_scores) > 0:\n",
    "        print(\"Creating Arsenal composite score radar chart...\")\n",
    "        \n",
    "        categories_clean = [c.replace('_', ' ').title() for c in arsenal_scores.keys()]\n",
    "        values = list(arsenal_scores.values())\n",
    "        \n",
    "        # Number of variables\n",
    "        num_vars = len(categories_clean)\n",
    "        \n",
    "        # Compute angle for each axis\n",
    "        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "        values += values[:1]  # Complete the circle\n",
    "        angles += angles[:1]\n",
    "        \n",
    "        # Create radar chart\n",
    "        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label='Arsenal', color='#EF0107')\n",
    "        ax.fill(angles, values, alpha=0.25, color='#EF0107')\n",
    "        \n",
    "        ax.set_xticks(angles[:-1])\n",
    "        ax.set_xticklabels(categories_clean, size=10)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.set_title(\"Arsenal's Composite Score Profile (GW7)\\nAll Categories\", \n",
    "                     fontsize=14, fontweight='bold', pad=20)\n",
    "        ax.grid(True)\n",
    "        ax.legend(loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / \"arsenal_composite_profile.png\", dpi=300, bbox_inches='tight')\n",
    "        print(\"‚úÖ Saved: arsenal_composite_profile.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Identify Arsenal's strengths and weaknesses\n",
    "        arsenal_scores_sorted = sorted(arsenal_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(\"üí™ ARSENAL'S STRENGTHS (Top 3):\")\n",
    "        for cat, score in arsenal_scores_sorted[:3]:\n",
    "            print(f\"  {cat.replace('_', ' ').title():<25} {score:.1f}\")\n",
    "        \n",
    "        print()\n",
    "        print(\"‚ö†Ô∏è  ARSENAL'S RELATIVE WEAKNESSES (Bottom 3):\")\n",
    "        for cat, score in arsenal_scores_sorted[-3:]:\n",
    "            print(f\"  {cat.replace('_', ' ').title():<25} {score:.1f}\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Arsenal data not available for current season\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 13: Comparing multiple teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 12B: MULTI-TEAM COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Define teams to compare\n",
    "teams_to_compare = ['Arsenal', 'Manchester City', 'Liverpool']\n",
    "\n",
    "# Create comparison radar chart\n",
    "if not current_wide.empty:\n",
    "    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "    # Team colors\n",
    "    team_colors = {\n",
    "        'Arsenal': '#EF0107',\n",
    "        'Manchester City': '#6CABDD',\n",
    "        'Liverpool': '#C8102E'\n",
    "    }\n",
    "\n",
    "    categories_clean = [c.replace('_', ' ').title() for c in categories]\n",
    "    num_vars = len(categories_clean)\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "\n",
    "    for team in teams_to_compare:\n",
    "        if team in current_wide['squad_name'].values:\n",
    "            team_row = current_wide[current_wide['squad_name'] == team].iloc[0]\n",
    "\n",
    "            # Get scores for all categories\n",
    "            team_values = [team_row[cat] for cat in categories]\n",
    "            team_values += team_values[:1]  # Complete the circle\n",
    "\n",
    "            # Plot\n",
    "            ax.plot(angles, team_values, 'o-', linewidth=2,\n",
    "                   label=team, color=team_colors.get(team, '#000000'))\n",
    "            ax.fill(angles, team_values, alpha=0.15,\n",
    "                   color=team_colors.get(team, '#000000'))\n",
    "\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories_clean, size=11)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_title(\"Top Teams Comparison (GW7)\\\\nComposite Score Profiles\",\n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / \"top_teams_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Saved: top_teams_comparison.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 14: Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SECTION 13: KEY FINDINGS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Create summary report\n",
    "summary_path = output_dir / \"composite_scores_summary.txt\"\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"COMPOSITE SCORES ANALYSIS SUMMARY - PART 1C\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"ANALYSIS SCOPE\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"Seasons analyzed: {len(seasons_to_analyze)}\\n\")\n",
    "    for season in seasons_to_analyze:\n",
    "        f.write(f\"  - {season}\\n\")\n",
    "    f.write(f\"Total squad-seasons: {len(historical_with_composites)}\\n\")\n",
    "    f.write(f\"Categories analyzed: {len(categories)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"STRONGEST PREDICTORS OF FINAL POSITION\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for i, (category, corr) in enumerate(correlations_sorted[:5], 1):\n",
    "        cat_name = category.replace('_score', '')\n",
    "        f.write(f\"{i}. {cat_name:<25} r = {corr:.3f}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"WEAKEST PREDICTORS (Consider Ignoring for ML)\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for category, corr in correlations_sorted[-3:]:\n",
    "        cat_name = category.replace('_score', '')\n",
    "        f.write(f\"  {cat_name:<25} r = {corr:.3f}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"CATEGORY SEPARATION (Top 4 vs Relegation)\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    for i, (category, sep) in enumerate(separations_sorted[:5], 1):\n",
    "        cat_name = category.replace('_score', '')\n",
    "        f.write(f\"{i}. {cat_name:<25} {sep:.1f} points difference\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    if not current_wide.empty and 'Arsenal' in current_wide['squad_name'].values:\n",
    "        f.write(\"ARSENAL'S DOMINANCE FACTORS (GW7)\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        for cat, score in arsenal_scores_sorted[:3]:\n",
    "            f.write(f\"  {cat.replace('_', ' ').title():<25} {score:.1f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"RECOMMENDATIONS FOR ML MODELING\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"1. PRIORITIZE these {len(top_predictors)} strong predictors (|r| ‚â• 0.5):\\n\")\n",
    "    for pred in top_predictors:\n",
    "        f.write(f\"   - {pred.replace('_score', '')}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(f\"2. CONSIDER IGNORING these {len(weak_predictors)} weak predictors (|r| < 0.3):\\n\")\n",
    "    for pred in weak_predictors:\n",
    "        f.write(f\"   - {pred.replace('_score', '')}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"3. Focus feature engineering on top predictors\\n\")\n",
    "    f.write(\"4. Test if weak predictors add any value in models\\n\")\n",
    "    f.write(\"5. Use historical separation data to weight features\\n\")\n",
    "\n",
    "print(f\"‚úÖ Summary saved to: {summary_path}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ PART 1C: COMPOSITE SCORES ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"üìÇ All outputs saved to: {output_dir}\")\n",
    "print(f\"\\nüìä Files created:\")\n",
    "print(f\"   - composite_scores_by_tier.png\")\n",
    "print(f\"   - composite_correlation_matrix.png\")\n",
    "print(f\"   - arsenal_composite_profile.png\")\n",
    "print(f\"   - composite_scores_summary.txt\")\n",
    "print()\n",
    "print(f\"üéØ Next: Review findings and proceed to Part 1D (Correlation Analysis)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
