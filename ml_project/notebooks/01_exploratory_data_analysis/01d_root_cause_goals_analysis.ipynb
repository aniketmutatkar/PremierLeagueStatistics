{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd552fef",
   "metadata": {},
   "source": [
    "# PART 1D: ROOT CAUSE ANALYSIS - What DRIVES Goals?\n",
    "\n",
    "## Objective\n",
    "Find ROOT CAUSES of goals (not just \"scoring more = winning more\") to:\n",
    "1. Weight composite scores by correlation strength\n",
    "2. Build match prediction features  \n",
    "3. Identify actionable tactical insights\n",
    "\n",
    "## Data\n",
    "- 5 seasons (2020-2025) at GW38\n",
    "- 100 team-seasons\n",
    "- Pearson correlations\n",
    "\n",
    "## Design\n",
    "- **Analysis 1**: Our offense ‚Üí Our goals\n",
    "- **Analysis 2**: Opponent offense ‚Üí Our goals_against"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e04c93",
   "metadata": {},
   "source": [
    "## Section 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "OUTPUT_DIR = Path(\"../../outputs/04_individual_stats\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PART 1D: ROOT CAUSE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚è∞ Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10213d7e",
   "metadata": {},
   "source": [
    "## Section 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = duckdb.connect('../../../data/premierleague_analytics.duckdb')\n",
    "\n",
    "squad_df = conn.execute(\"\"\"\n",
    "    SELECT * FROM analytics_squads\n",
    "    WHERE season IN ('2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025')\n",
    "      AND gameweek = 38\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "opponent_df = conn.execute(\"\"\"\n",
    "    SELECT * FROM analytics_opponents\n",
    "    WHERE season IN ('2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025')\n",
    "      AND gameweek = 38\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "opponent_df['squad_name_clean'] = opponent_df['squad_name'].str.replace('vs ', '', regex=False)\n",
    "\n",
    "# Calculate tiers\n",
    "squad_df['points'] = (squad_df['wins'] * 3) + squad_df['draws']\n",
    "squad_df['goal_difference'] = squad_df['goals'] - squad_df['goals_against']\n",
    "squad_df['final_position'] = squad_df.groupby('season')['points'].rank(method='min', ascending=False).astype(int)\n",
    "squad_df['tier'] = squad_df['final_position'].apply(lambda p: 'Top 4' if p <= 4 else ('Mid-Table' if p <= 17 else 'Relegation'))\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(squad_df)} squads, {len(opponent_df)} opponents\")\n",
    "print(f\"   Tiers: {dict(squad_df['tier'].value_counts())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea4ad2",
   "metadata": {},
   "source": [
    "## Section 3: Define Stat Exclusions (Avoid Circular Reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81fb93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_exclusions = [\n",
    "    'goals', 'goals_per_90', 'non_penalty_goals', 'non_penalty_goals_per_90', 'goal_difference', 'points',\n",
    "    'penalty_kicks_made', 'penalty_kicks_attempted',\n",
    "    'assists', 'assists_per_90', 'assists_passing',\n",
    "    'goals_plus_assists', 'goals_plus_assists_per_90', 'goals_plus_assists_minus_pks_per_90',\n",
    "    'expected_goals', 'expected_goals_per_90', 'non_penalty_expected_goals', 'non_penalty_xg_per_90',\n",
    "    'expected_assisted_goals', 'expected_assisted_goals_per_90',\n",
    "    'xg_plus_xag_per_90', 'non_penalty_xg_plus_xag', 'non_penalty_xg_plus_xag_per_90',\n",
    "    'non_penalty_goals_minus_expected',\n",
    "    'goal_creating_actions', 'goal_creating_actions_per_90',\n",
    "    'gca_pass_live', 'gca_pass_dead', 'gca_take_on', 'gca_shot', 'gca_defense', 'gca_fouled'\n",
    "]\n",
    "\n",
    "goals_against_exclusions = [\n",
    "    'goals_against', 'goals_against_per_90', 'clean_sheets', 'clean_sheet_percentage',\n",
    "    'saves', 'save_percentage', 'shots_on_target_against',\n",
    "    'post_shot_expected_goals', 'post_shot_xg_per_shot',\n",
    "    'post_shot_xg_performance', 'post_shot_xg_performance_per_90'\n",
    "]\n",
    "\n",
    "metadata = ['squad_name', 'season', 'gameweek', 'is_current', 'age', 'matches_played', 'wins', 'draws', 'losses']\n",
    "predictors = [c for c in squad_df.columns\n",
    "             if c not in metadata + goal_exclusions + goals_against_exclusions\n",
    "             and squad_df[c].dtype in ['int64', 'float64']]\n",
    "\n",
    "print(f\"‚úÖ Analyzing {len(predictors)} predictors\")\n",
    "print(f\"   Excluded {len(goal_exclusions)} circular stats (goals, assists, xG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04758886",
   "metadata": {},
   "source": [
    "## Section 4: Analysis 1 - What Drives Goals SCORED?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e150ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ANALYSIS 1: WHAT DRIVES GOALS SCORED?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "goals_results = []\n",
    "for stat in predictors:\n",
    "    valid = squad_df[[stat, 'goals']].dropna()\n",
    "    if len(valid) < 10 or valid[stat].std() == 0:\n",
    "        continue\n",
    "    r, p = pearsonr(valid[stat], valid['goals'])\n",
    "    goals_results.append({'stat': stat, 'r': r, 'p': p, 'abs_r': abs(r)})\n",
    "\n",
    "goals_df = pd.DataFrame(goals_results).sort_values('abs_r', ascending=False)\n",
    "print(f\"\\n‚úÖ {len(goals_df)} correlations calculated\")\n",
    "\n",
    "print(f\"\\nTOP 10 DRIVERS:\")\n",
    "for i, row in goals_df.head(10).iterrows():\n",
    "    strength = 'üî•üî•üî•' if row['abs_r'] >= 0.8 else 'üî•üî•' if row['abs_r'] >= 0.6 else 'üí™'\n",
    "    print(f\"  {row['stat']:<45} r = {row['r']:>6.3f}  {strength}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13d320",
   "metadata": {},
   "source": [
    "## Section 5: Analysis 2 - What Drives Goals AGAINST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ANALYSIS 2: WHAT DRIVES GOALS AGAINST?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "merged_opp = pd.merge(\n",
    "    squad_df[['season', 'squad_name', 'goals_against', 'tier']],\n",
    "    opponent_df[['season', 'squad_name_clean'] + [c for c in predictors if c in opponent_df.columns]],\n",
    "    left_on=['season', 'squad_name'],\n",
    "    right_on=['season', 'squad_name_clean'],\n",
    "    suffixes=('', '_opp')\n",
    ")\n",
    "\n",
    "opp_results = []\n",
    "for stat in predictors:\n",
    "    if stat not in merged_opp.columns:\n",
    "        continue\n",
    "    valid = merged_opp[[stat, 'goals_against']].dropna()\n",
    "    if len(valid) < 10 or valid[stat].std() == 0:\n",
    "        continue\n",
    "    r, p = pearsonr(valid[stat], valid['goals_against'])\n",
    "    opp_results.append({'stat': f\"OPP_{stat}\", 'source': 'opponent', 'r': r, 'p': p, 'abs_r': abs(r)})\n",
    "\n",
    "defense_df = pd.DataFrame(opp_results).sort_values('abs_r', ascending=False)\n",
    "print(f\"\\n‚úÖ {len(defense_df)} opponent correlations calculated\")\n",
    "\n",
    "print(f\"\\nTOP 10 DEFENSIVE DRIVERS:\")\n",
    "for i, row in defense_df.head(10).iterrows():\n",
    "    strength = 'üî•üî•üî•' if row['abs_r'] >= 0.8 else 'üî•üî•' if row['abs_r'] >= 0.6 else 'üí™'\n",
    "    print(f\"  {row['stat']:<45} r = {row['r']:>6.3f}  {strength}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0dad0",
   "metadata": {},
   "source": [
    "## Section 6: Category-Level Analysis\n",
    "\n",
    "### 6.1 Categorize Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize stats by type\n",
    "def categorize_stat(stat):\n",
    "    stat_lower = stat.lower()\n",
    "    \n",
    "    if any(x in stat_lower for x in ['shot', 'touch_att_pen']):\n",
    "        return 'attacking_output'\n",
    "    elif any(x in stat_lower for x in ['key_pass', 'sca_', 'corner', 'through_ball', 'cross']):\n",
    "        return 'creativity'\n",
    "    elif any(x in stat_lower for x in ['pass_complet', 'pass_attempt', 'pass_distance', 'progressive_pass']):\n",
    "        return 'passing'\n",
    "    elif any(x in stat_lower for x in ['carry', 'progressive_carri', 'progressive_passes_received', 'take_on']):\n",
    "        return 'ball_progression'\n",
    "    elif any(x in stat_lower for x in ['tackle', 'interception', 'block', 'clearance']):\n",
    "        return 'defending'\n",
    "    elif any(x in stat_lower for x in ['touch', 'possession']):\n",
    "        return 'possession'\n",
    "    elif any(x in stat_lower for x in ['aerial', 'duel', 'foul']):\n",
    "        return 'physical_duels'\n",
    "    elif any(x in stat_lower for x in ['error', 'miscontr', 'dispossess', 'challenge_lost']):\n",
    "        return 'failures'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "goals_df['category'] = goals_df['stat'].apply(categorize_stat)\n",
    "\n",
    "# Calculate category-level stats\n",
    "category_stats = goals_df.groupby('category').agg({\n",
    "    'abs_r': ['mean', 'max'],\n",
    "    'stat': 'count'\n",
    "}).round(3)\n",
    "\n",
    "category_stats.columns = ['avg_r', 'max_r', 'n_stats']\n",
    "category_stats = category_stats.sort_values('avg_r', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CATEGORY ANALYSIS - Which Stat Types Matter Most?\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(category_stats)\n",
    "print()\n",
    "print(f\"üí° {category_stats.index[0]}: Strongest average correlation (r = {category_stats.iloc[0]['avg_r']:.3f})\")\n",
    "print(f\"üí° {category_stats.index[-1]}: Weakest predictor (r = {category_stats.iloc[-1]['avg_r']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf714d9a",
   "metadata": {},
   "source": [
    "### 6.2 Visualize Category Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of category strengths\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "category_plot = category_stats.sort_values('avg_r', ascending=True)\n",
    "colors_cat = plt.cm.viridis(np.linspace(0.3, 0.9, len(category_plot)))\n",
    "\n",
    "bars = ax.barh(category_plot.index, category_plot['avg_r'], color=colors_cat, alpha=0.8)\n",
    "\n",
    "# Add max_r markers\n",
    "ax.scatter(category_plot['max_r'], range(len(category_plot)), \n",
    "          color='red', s=100, marker='D', label='Max r in category', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Average Correlation Strength (|r|)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Stat Category', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Which Stat Categories Best Predict Goals Scored?', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(category_plot.iterrows()):\n",
    "    ax.text(row['avg_r'] + 0.01, i, f\"{row['avg_r']:.3f} (n={int(row['n_stats'])})\", \n",
    "           va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"category_correlations.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: category_correlations.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c280117",
   "metadata": {},
   "source": [
    "## Section 7: Visualize Top Drivers\n",
    "\n",
    "### 7.1 Offensive Drivers Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca114e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots for top 6 offensive drivers\n",
    "top_drivers = goals_df.head(6)['stat'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "tier_colors = {'Top 4': '#2ecc71', 'Mid-Table': '#3498db', 'Relegation': '#e74c3c'}\n",
    "\n",
    "for idx, stat in enumerate(top_drivers):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot by tier\n",
    "    for tier in ['Top 4', 'Mid-Table', 'Relegation']:\n",
    "        data = squad_df[squad_df['tier'] == tier]\n",
    "        ax.scatter(data[stat], data['goals'], \n",
    "                  label=tier, alpha=0.6, s=60, color=tier_colors[tier])\n",
    "    \n",
    "    # Add regression line\n",
    "    valid = squad_df[[stat, 'goals']].dropna()\n",
    "    if len(valid) > 0 and valid[stat].std() > 0:\n",
    "        z = np.polyfit(valid[stat], valid['goals'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(valid[stat].min(), valid[stat].max(), 100)\n",
    "        ax.plot(x_line, p(x_line), 'k--', alpha=0.3, linewidth=2)\n",
    "    \n",
    "    # Get correlation\n",
    "    r_val = goals_df[goals_df['stat'] == stat]['r'].iloc[0]\n",
    "    \n",
    "    ax.set_xlabel(stat, fontsize=10)\n",
    "    ax.set_ylabel('Goals Scored', fontsize=10)\n",
    "    ax.set_title(f'{stat}\\nr = {r_val:.3f}', fontsize=11, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "\n",
    "plt.suptitle('Top 6 Offensive Drivers of Goals Scored', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"scatter_offensive_drivers.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: scatter_offensive_drivers.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933c25a",
   "metadata": {},
   "source": [
    "### 7.2 Defensive Drivers Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a6fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots for top 6 defensive drivers\n",
    "top_def_drivers = defense_df.head(6)['stat'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, opp_stat in enumerate(top_def_drivers):\n",
    "    ax = axes[idx]\n",
    "    base_stat = opp_stat.replace('OPP_', '')\n",
    "    \n",
    "    if base_stat not in merged_opp.columns:\n",
    "        continue\n",
    "    \n",
    "    # Plot by tier\n",
    "    for tier in ['Top 4', 'Mid-Table', 'Relegation']:\n",
    "        data = merged_opp[merged_opp['tier'] == tier]\n",
    "        ax.scatter(data[base_stat], data['goals_against'], \n",
    "                  label=tier, alpha=0.6, s=60, color=tier_colors[tier])\n",
    "    \n",
    "    # Add regression line\n",
    "    valid = merged_opp[[base_stat, 'goals_against']].dropna()\n",
    "    if len(valid) > 0 and valid[base_stat].std() > 0:\n",
    "        z = np.polyfit(valid[base_stat], valid['goals_against'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(valid[base_stat].min(), valid[base_stat].max(), 100)\n",
    "        ax.plot(x_line, p(x_line), 'k--', alpha=0.3, linewidth=2)\n",
    "    \n",
    "    # Get correlation\n",
    "    r_val = defense_df[defense_df['stat'] == opp_stat]['r'].iloc[0]\n",
    "    \n",
    "    ax.set_xlabel(opp_stat, fontsize=9)\n",
    "    ax.set_ylabel('Goals Against', fontsize=10)\n",
    "    ax.set_title(f'{opp_stat}\\nr = {r_val:.3f}', fontsize=11, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    if idx == 0:\n",
    "        ax.legend(loc='best', fontsize=8)\n",
    "\n",
    "plt.suptitle('Top 6 Drivers of Goals Against (Opponent Offensive Stats)', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"scatter_defensive_drivers.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: scatter_defensive_drivers.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b1075",
   "metadata": {},
   "source": [
    "## Section 8: Tier-Based Analysis\n",
    "\n",
    "### 8.1 Different Tiers, Different Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a06a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations by tier\n",
    "def tier_correlations(tier_name):\n",
    "    tier_data = squad_df[squad_df['tier'] == tier_name]\n",
    "    results = []\n",
    "    \n",
    "    for stat in predictors:\n",
    "        valid = tier_data[[stat, 'goals']].dropna()\n",
    "        if len(valid) < 5 or valid[stat].std() == 0:\n",
    "            continue\n",
    "        r, p = pearsonr(valid[stat], valid['goals'])\n",
    "        results.append({'stat': stat, 'r': r, 'p': p, 'abs_r': abs(r)})\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('abs_r', ascending=False)\n",
    "\n",
    "top4_corr = tier_correlations('Top 4')\n",
    "relegation_corr = tier_correlations('Relegation')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TIER-BASED DRIVER ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"üèÜ TOP 4 TEAMS - Top 5 Drivers:\")\n",
    "print(\"-\" * 80)\n",
    "for i, (idx, row) in enumerate(top4_corr.head(5).iterrows(), 1):\n",
    "    print(f\"{i}. {row['stat']:<45} r = {row['r']:>6.3f}\")\n",
    "print()\n",
    "\n",
    "print(\"‚ö†Ô∏è  RELEGATION TEAMS - Top 5 Drivers:\")\n",
    "print(\"-\" * 80)\n",
    "for i, (idx, row) in enumerate(relegation_corr.head(5).iterrows(), 1):\n",
    "    print(f\"{i}. {row['stat']:<45} r = {row['r']:>6.3f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abac9b2",
   "metadata": {},
   "source": [
    "### 8.2 Visualize Tier Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64dfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare top drivers between tiers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 4 drivers\n",
    "ax = axes[0]\n",
    "top_stats = top4_corr.head(10).sort_values('r', ascending=True)\n",
    "colors_t4 = ['green' if r > 0 else 'red' for r in top_stats['r']]\n",
    "ax.barh(range(len(top_stats)), top_stats['r'], color=colors_t4, alpha=0.7)\n",
    "ax.set_yticks(range(len(top_stats)))\n",
    "ax.set_yticklabels(top_stats['stat'], fontsize=9)\n",
    "ax.set_xlabel('Correlation (r)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Top 4 Teams: What Drives Goals?', fontsize=13, fontweight='bold')\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Relegation drivers\n",
    "ax = axes[1]\n",
    "rel_stats = relegation_corr.head(10).sort_values('r', ascending=True)\n",
    "colors_rel = ['green' if r > 0 else 'red' for r in rel_stats['r']]\n",
    "ax.barh(range(len(rel_stats)), rel_stats['r'], color=colors_rel, alpha=0.7)\n",
    "ax.set_yticks(range(len(rel_stats)))\n",
    "ax.set_yticklabels(rel_stats['stat'], fontsize=9)\n",
    "ax.set_xlabel('Correlation (r)', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Relegation Teams: What Drives Goals?', fontsize=13, fontweight='bold')\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.suptitle('Different Tiers, Different Drivers', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"tier_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: tier_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12de76",
   "metadata": {},
   "source": [
    "## Section 9: Statistical Significance\n",
    "\n",
    "### 9.1 Test Correlation Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ec64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add significance markers\n",
    "def sig_marker(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "goals_df['sig'] = goals_df['p'].apply(sig_marker)\n",
    "\n",
    "# Count by significance level\n",
    "sig_counts = goals_df['sig'].value_counts()\n",
    "total = len(goals_df)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTING\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"Total correlations tested: {total}\")\n",
    "print(f\"  *** (p < 0.001): {sig_counts.get('***', 0):3} ({100*sig_counts.get('***', 0)/total:.1f}%)\")\n",
    "print(f\"  **  (p < 0.01):  {sig_counts.get('**', 0):3} ({100*sig_counts.get('**', 0)/total:.1f}%)\")\n",
    "print(f\"  *   (p < 0.05):  {sig_counts.get('*', 0):3} ({100*sig_counts.get('*', 0)/total:.1f}%)\")\n",
    "print(f\"  ns  (p ‚â• 0.05):  {sig_counts.get('ns', 0):3} ({100*sig_counts.get('ns', 0)/total:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Strong + significant\n",
    "strong_sig = goals_df[(goals_df['abs_r'] >= 0.6) & (goals_df['p'] < 0.001)]\n",
    "print(f\"üéØ Strong + highly significant (|r| ‚â• 0.6, p < 0.001): {len(strong_sig)}/{total}\")\n",
    "print()\n",
    "\n",
    "# Save correlations to CSV\n",
    "goals_df.to_csv(OUTPUT_DIR / \"goals_scored_correlations.csv\", index=False)\n",
    "defense_df['sig'] = defense_df['p'].apply(sig_marker)\n",
    "defense_df.to_csv(OUTPUT_DIR / \"goals_against_correlations.csv\", index=False)\n",
    "print(\"‚úÖ Saved: goals_scored_correlations.csv\")\n",
    "print(\"‚úÖ Saved: goals_against_correlations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33bf2ae",
   "metadata": {},
   "source": [
    "### 9.2 Volcano Plot (Strength vs Significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7920468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcano plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Calculate -log10(p) for y-axis\n",
    "goals_df['-log10_p'] = -np.log10(goals_df['p'])\n",
    "\n",
    "# Color by strength + significance\n",
    "def get_color(row):\n",
    "    if row['abs_r'] >= 0.6 and row['p'] < 0.001:\n",
    "        return '#2ecc71'  # Strong + highly significant\n",
    "    elif row['abs_r'] >= 0.4 and row['p'] < 0.05:\n",
    "        return '#3498db'  # Moderate + significant\n",
    "    elif row['p'] < 0.05:\n",
    "        return '#f39c12'  # Weak but significant\n",
    "    else:\n",
    "        return '#95a5a6'  # Not significant\n",
    "\n",
    "goals_df['color'] = goals_df.apply(get_color, axis=1)\n",
    "\n",
    "# Scatter plot\n",
    "scatter = ax.scatter(goals_df['r'], goals_df['-log10_p'], \n",
    "                    c=goals_df['color'], s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add threshold lines\n",
    "ax.axhline(-np.log10(0.05), color='red', linestyle='--', alpha=0.5, label='p = 0.05')\n",
    "ax.axhline(-np.log10(0.001), color='darkred', linestyle='--', alpha=0.5, label='p = 0.001')\n",
    "ax.axvline(0.6, color='green', linestyle='--', alpha=0.5, label='|r| = 0.6')\n",
    "ax.axvline(-0.6, color='green', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Labels for top stats\n",
    "top_labeled = goals_df.nlargest(5, 'abs_r')\n",
    "for idx, row in top_labeled.iterrows():\n",
    "    ax.annotate(row['stat'], (row['r'], row['-log10_p']), \n",
    "               fontsize=8, alpha=0.7, xytext=(5, 5), textcoords='offset points')\n",
    "\n",
    "ax.set_xlabel('Correlation Coefficient (r)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('-log‚ÇÅ‚ÇÄ(p-value)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Statistical Significance vs Correlation Strength\\n(Volcano Plot)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend for colors\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#2ecc71', label='Strong + Sig (|r|‚â•0.6, p<0.001)'),\n",
    "    Patch(facecolor='#3498db', label='Moderate + Sig (|r|‚â•0.4, p<0.05)'),\n",
    "    Patch(facecolor='#f39c12', label='Weak but Sig (p<0.05)'),\n",
    "    Patch(facecolor='#95a5a6', label='Not Significant')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper left', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"statistical_significance.png\", dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Saved: statistical_significance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0b71a",
   "metadata": {},
   "source": [
    "## Section 10: Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd23a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary report\n",
    "print(\"=\" * 80)\n",
    "print(\"GENERATING SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "summary_path = OUTPUT_DIR / \"summary_report.txt\"\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"=\" * 100 + \"\\n\")\n",
    "    f.write(\"PART 1D: ROOT CAUSE ANALYSIS - WHAT DRIVES GOALS?\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"DESIGN:\\n\")\n",
    "    f.write(\"- Analysis 1: What drives OUR goals scored\\n\")\n",
    "    f.write(\"- Analysis 2: What drives goals AGAINST us (opponent offensive actions)\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\" * 100 + \"\\n\")\n",
    "    f.write(\"RESULTS\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP 10 DRIVERS OF GOALS SCORED:\\n\")\n",
    "    for i, (idx, row) in enumerate(goals_df.head(10).iterrows(), 1):\n",
    "        f.write(f\"   {i:2}. {row['stat']:<45} r = {row['r']:>6.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\nTOP 20 DRIVERS OF GOALS AGAINST:\\n\")\n",
    "    for i, (idx, row) in enumerate(defense_df.head(20).iterrows(), 1):\n",
    "        f.write(f\"   {i:2}. {row['stat']:<45} r = {row['r']:>6.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "    f.write(\"CATEGORY ANALYSIS\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    f.write(category_stats.to_string())\n",
    "    \n",
    "    f.write(\"\\n\\n\" + \"=\" * 100 + \"\\n\")\n",
    "    f.write(\"TIER COMPARISON\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"TOP 4 TEAMS - Top 5 Drivers:\\n\")\n",
    "    for i, (idx, row) in enumerate(top4_corr.head(5).iterrows(), 1):\n",
    "        f.write(f\"  {row['stat']:<45} r = {row['r']:>6.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\nRELEGATION TEAMS - Top 5 Drivers:\\n\")\n",
    "    for i, (idx, row) in enumerate(relegation_corr.head(5).iterrows(), 1):\n",
    "        f.write(f\"  {row['stat']:<45} r = {row['r']:>6.3f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\\n\" + \"=\" * 100 + \"\\n\")\n",
    "    f.write(\"STATISTICAL SIGNIFICANCE\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    \n",
    "    sig_total = sig_counts.get('***', 0) + sig_counts.get('**', 0) + sig_counts.get('*', 0)\n",
    "    f.write(f\"Significant correlations (p<0.05): {sig_total}/{total}\\n\")\n",
    "    f.write(f\"Strong + significant (|r|‚â•0.6, p<0.001): {len(strong_sig)}/{total}\\n\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "    f.write(\"APPLICATIONS\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\")\n",
    "    f.write(\"1. COMPOSITE WEIGHTS: Use |r| to weight stats in composites\\n\")\n",
    "    f.write(\"2. MATCH PREDICTION: Model both sides:\\n\")\n",
    "    f.write(\"   - Our goals = f(our offense)\\n\")\n",
    "    f.write(\"   - Their goals = f(their offense)\\n\")\n",
    "    f.write(\"   - Adjust for opponent defensive quality\\n\")\n",
    "\n",
    "print(f\"‚úÖ Saved comprehensive summary: {summary_path}\")\n",
    "print()\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ PART 1D: ROOT CAUSE ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"üìÇ All outputs saved to: {OUTPUT_DIR}\")\n",
    "print()\n",
    "print(\"üìä Files created:\")\n",
    "print(\"   - goals_scored_correlations.csv\")\n",
    "print(\"   - goals_against_correlations.csv\")\n",
    "print(\"   - scatter_offensive_drivers.png\")\n",
    "print(\"   - scatter_defensive_drivers.png\")\n",
    "print(\"   - category_correlations.png\")\n",
    "print(\"   - tier_comparison.png\")\n",
    "print(\"   - statistical_significance.png\")\n",
    "print(\"   - summary_report.txt\")\n",
    "print()\n",
    "print(\"üéØ Key Takeaways:\")\n",
    "print(f\"   - {len(strong_sig)} stats strongly predict goals (|r|‚â•0.6, p<0.001)\")\n",
    "print(f\"   - {category_stats.index[0]} is the strongest category (avg r = {category_stats.iloc[0]['avg_r']:.3f})\")\n",
    "print(\"   - Top 4 vs Relegation teams have DIFFERENT goal drivers\")\n",
    "print(\"   - Opponent offense strongly predicts our goals against\")\n",
    "print()\n",
    "print(\"üöÄ Next: Use these correlations for match prediction and composite weighting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
