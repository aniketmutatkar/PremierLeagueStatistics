# Scraping Configuration
scraping:
  # Rate limiting (be respectful to FBRef)
  delays:
    between_requests: 10  # seconds between requests
    on_error: 30         # seconds to wait after an error
    
  # Simple retry logic
  retries:
    max_attempts: 3
    backoff_factor: 2    # exponential backoff: 2, 4, 8 seconds
    
  # HTTP settings
  http:
    timeout: 30
    user_agents:
      - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
      - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15"
      - "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Mobile Safari/537.3"
    headers:
      Accept: "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
      Accept-Language: "en-US,en;q=0.5"
      Connection: "keep-alive"
      
  # Simple validation - just catch obvious errors
  validation:
    required_columns: true     # Make sure expected columns exist
    non_empty_tables: true     # Tables shouldn't be completely empty
    duplicate_detection: true  # No duplicate players per gameweek
    
  # Basic logging
  logging:
    level: "INFO"
    file: "data/scraping.log"